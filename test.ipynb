{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302ec297",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5540ae",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea857fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = np.load('/home/souryas2/new_idea/sksbks_2/data/sp_val.npy')\n",
    "sa = np.load('/home/souryas2/new_idea/sksbks_2/data/sa_val.npy')\n",
    "data = np.concatenate([sp, sa])\n",
    "sp_lab = np.ones(len(sp))\n",
    "sa_lab = np.zeros(len(sa))\n",
    "labels = np.concatenate([sp_lab,sa_lab])\n",
    "arr = np.arange(len(data))\n",
    "np.random.seed(101)\n",
    "np.random.shuffle(arr)\n",
    "data_valid = data[arr]\n",
    "labels_valid = labels[arr]\n",
    "data_valid = data_valid.astype('float32')\n",
    "im_size = sp.shape[1]\n",
    "data_valid = np.reshape(data_valid, [-1, im_size, im_size, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38abb4",
   "metadata": {},
   "source": [
    "# Parameter Loading (total1 = total Conv layer in black-box model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddde36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total1 = 2\n",
    "padding1 = 'same'\n",
    "best_blackbox_ckpt = '/home/souryas2/new_idea/sksbks_2/github'\n",
    "best_interpretable_ckpt = '/home/souryas2/new_idea/sksbks_2/github'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515d9ac",
   "metadata": {},
   "source": [
    "# Loading both Classification and Estimation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a77c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from skimage.util.shape import view_as_windows\n",
    "import glob\n",
    "from os import walk\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input, Conv2D, MaxPooling2D, concatenate, Lambda, Deconvolution2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "# Define Mish Activation Function\n",
    "def mish(x):\n",
    "    return Lambda(lambda x: x * tf.tanh(tf.log(1 + tf.exp(x))))(x)\n",
    "\n",
    "# Custom ReLU function with maximum value constraint\n",
    "def create_relu_advanced(max_value=1.):\n",
    "    def relu_advanced(x):\n",
    "        return K.relu(x, max_value=K.cast_to_floatx(max_value))\n",
    "    return relu_advanced\n",
    "\n",
    "\n",
    "activation1 = mish\n",
    "\n",
    "input_size = (im_size, im_size, 1)\n",
    "n = total1\n",
    "\n",
    "# Building the initial CNN model\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv2D(64, 5, padding='same', activation='relu')(inputs)\n",
    "\n",
    "for _ in range(n - 1):\n",
    "    conv1 = Conv2D(128, 5, padding='same', activation='relu')(conv1)\n",
    "\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "out = Flatten()(pool2)\n",
    "out = Dense(64)(out)\n",
    "predictions = Dense(1, activation='sigmoid')(out)\n",
    "model1 = Model(input=inputs, output=predictions)\n",
    "\n",
    "ckpt_path = best_blackbox_ckpt \n",
    "best_ckpt = os.path.join(ckpt_path, 'best_model.hdf5')\n",
    "model1.load_weights(best_ckpt)\n",
    "\n",
    "max3 = model1.layers[-4].output\n",
    "conv4 = Deconvolution2D(64, (2, 2), strides=2)(max3)\n",
    "conv5 = Conv2D(64, 5, activation=activation1, padding='same', use_bias=False)(conv4)\n",
    "conv5 = concatenate([conv5, model1.layers[-5].output])\n",
    "\n",
    "for t1 in range(1, total1):\n",
    "    conv5 = Conv2D(64, 5, activation=activation1, padding=padding1, use_bias=False)(conv5)\n",
    "\n",
    "conv7 = Conv2D(1, 5, activation=activation1, padding='same', use_bias=False)(conv5)\n",
    "flat2 = Flatten()(conv7)\n",
    "dense2 = Dense(1, activation=create_relu_advanced(max_value=1.), use_bias=False)(flat2)\n",
    "\n",
    "# Final model definition\n",
    "model_test3 = Model(input=model1.input, output=dense2)\n",
    "\n",
    "# Freezing layers based on 'trainable1' argument\n",
    "for layer in model_test3.layers[:6]:\n",
    "    layer.trainable = False\n",
    "for layer in model_test3.layers[6:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compiling the model\n",
    "model_test3.compile(optimizer=Adam(lr=1e-4, clipvalue=0.5), loss='mean_squared_error', metrics=['mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee5359",
   "metadata": {},
   "source": [
    "# Load the model weights and compare accuracy and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31beab8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1.compile(optimizer = Adam(lr = 1e-4),  loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "ckpt_path = best_blackbox_ckpt \n",
    "best_ckpt = os.path.join(ckpt_path, 'best_model.hdf5')\n",
    "model1.load_weights(best_ckpt)\n",
    "model1.evaluate(data_valid, labels_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a43205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_prediction_r = []\n",
    "test_labels_r = []\n",
    "ckpt_path =  best_interpretable_ckpt\n",
    "best_ckpt = os.path.join(ckpt_path, 'best_selfinterpretable_model.hdf5')\n",
    "model_test3.load_weights(best_ckpt)\n",
    "\n",
    "for t1 in data_valid:\n",
    "    \n",
    "    prob = model_test3.predict(np.reshape(t1,[-1, im_size, im_size, 1]))[0]\n",
    "    test_prediction_r.append(prob)\n",
    "    \n",
    "count = 0\n",
    "for t1 in range(len(test_prediction_r)):\n",
    "    if test_prediction_r[t1] > 0.5 and labels_valid[t1] == 1:\n",
    "        count = count + 1\n",
    "    if test_prediction_r[t1] < 0.5 and labels_valid[t1] == 0:\n",
    "        count = count + 1\n",
    "        \n",
    "print(count/len(labels_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c802677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "best_ckpt = os.path.join(ckpt_path, 'best_model.hdf5')\n",
    "model1.load_weights(best_ckpt)\n",
    "pred_bb = model1.predict(data_valid)\n",
    "\n",
    "best_ckpt = os.path.join(ckpt_path, 'best_selfinterpretable_model.hdf5')\n",
    "model_test3.load_weights(best_ckpt)\n",
    "pred_si = model_test3.predict(data_valid)\n",
    "\n",
    "# Compute the ROC curve\n",
    "fpr_bb, tpr_bb, thresholds_bb = roc_curve(labels_valid, pred_bb)\n",
    "fpr_si, tpr_si, thresholds_si = roc_curve(labels_valid, pred_si)\n",
    "\n",
    "\n",
    "plt.figure()  # Adjust the figure size and DPI for clarity\n",
    "plt.plot(fpr_bb, tpr_bb, label=f'Black-Box Classifier (AUC = {auc(fpr_bb, tpr_bb):.2f})', color='blue')\n",
    "plt.plot(fpr_si, tpr_si, label=f'Self-Interpretable (AUC = {auc(fpr_si, tpr_si):.2f})', color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ROC Curve Comparison', fontsize=14)\n",
    "\n",
    "# Add a legend with a larger font size\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a062110",
   "metadata": {},
   "source": [
    "# Visualizing E-maps for abnormal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd878c5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = 331 \n",
    "data_valid_1 = sp[t]\n",
    "best_ckpt = os.path.join(ckpt_path, 'best_selfinterpretable_model.hdf5')\n",
    "model_test3.load_weights(best_ckpt)\n",
    "\n",
    "model_map_relu = Model(inputs=model_test3.inputs, outputs=model_test3.layers[-3].output)\n",
    "\n",
    "feature_maprelu = model_map_relu.predict(np.reshape(data_valid_1.astype('float32'),[-1,im_size,im_size,1]))\n",
    "weights = model_test3.layers[-1].get_weights()[0]\n",
    "weights_reshape = np.reshape(weights,[im_size,im_size])\n",
    "feat = np.reshape(feature_maprelu,[im_size, im_size])\n",
    "feat2 = np.multiply(feat,weights_reshape)\n",
    "\n",
    "\n",
    "feat3_1 =  cv2.GaussianBlur(feat2,(19,19), cv2.BORDER_DEFAULT)\n",
    "\n",
    "\n",
    "plt.imshow((data_valid_1),cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow((data_valid_1),cmap='gray')\n",
    "plt.imshow(feat3_1, cmap='jet', alpha = 0.6)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "print(model_test3.predict(np.reshape(data_valid_1,[-1,im_size,im_size,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0acbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
